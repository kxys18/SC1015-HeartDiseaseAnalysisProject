{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c79d63-47c5-4483-88e9-5a9c927fa7df",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Random forest is an ensemble learning method that operates by constructing multiple decision trees during training and outputting categories as patterns of classification categories. To increase the probability of detecting patients with the disease, we innovatively customized the voting mechanism of the Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e27b9e-de63-465d-8d4a-94db60be6e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuxiaotao\\AppData\\Local\\Temp\\ipykernel_17660\\236778582.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() \n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0191c72-f928-4f17-82fd-722e2512825f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  General_Health                  Checkup Exercise Heart_Disease Skin_Cancer  \\\n",
      "0           Poor  Within the past 2 years       No            No          No   \n",
      "1      Very Good     Within the past year       No           Yes          No   \n",
      "2      Very Good     Within the past year      Yes            No          No   \n",
      "3           Poor     Within the past year      Yes           Yes          No   \n",
      "4           Good     Within the past year       No            No          No   \n",
      "\n",
      "  Other_Cancer Depression Diabetes Arthritis     Sex Age_Category  \\\n",
      "0           No         No       No       Yes  Female        70-74   \n",
      "1           No         No      Yes        No  Female        70-74   \n",
      "2           No         No      Yes        No  Female        60-64   \n",
      "3           No         No      Yes        No    Male        75-79   \n",
      "4           No         No       No        No    Male          80+   \n",
      "\n",
      "   Height_(cm)  Weight_(kg)    BMI Smoking_History  Alcohol_Consumption  \\\n",
      "0        150.0        32.66  14.54             Yes                  0.0   \n",
      "1        165.0        77.11  28.29              No                  0.0   \n",
      "2        163.0        88.45  33.47              No                  4.0   \n",
      "3        180.0        93.44  28.73              No                  0.0   \n",
      "4        191.0        88.45  24.37             Yes                  0.0   \n",
      "\n",
      "   Fruit_Consumption  Green_Vegetables_Consumption  FriedPotato_Consumption  \n",
      "0               30.0                          16.0                     12.0  \n",
      "1               30.0                           0.0                      4.0  \n",
      "2               12.0                           3.0                     16.0  \n",
      "3               30.0                          30.0                      8.0  \n",
      "4                8.0                           4.0                      0.0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('CVD_cleaned.csv')\n",
    "\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b16d1ee-789b-4fef-a617-69c25b4ae100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Label catogary data\n",
    "df['General_Health'] = label_encoder.fit_transform(df['General_Health'])\n",
    "df['Checkup'] = label_encoder.fit_transform(df['Checkup'])\n",
    "df['Exercise'] = label_encoder.fit_transform(df['Exercise'])\n",
    "df['Skin_Cancer'] = label_encoder.fit_transform(df['Skin_Cancer'])\n",
    "df['Other_Cancer'] = label_encoder.fit_transform(df['Other_Cancer'])\n",
    "df['Depression'] = label_encoder.fit_transform(df['Depression'])\n",
    "df['Diabetes'] = label_encoder.fit_transform(df['Diabetes'])\n",
    "df['Arthritis'] = label_encoder.fit_transform(df['Arthritis'])\n",
    "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
    "df['Age_Category'] = label_encoder.fit_transform(df['Age_Category'])\n",
    "df['Heart_Disease'] = label_encoder.fit_transform(df['Heart_Disease'])\n",
    "df['Smoking_History'] = label_encoder.fit_transform(df['Smoking_History'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb9f98-a8a8-40b2-b2d1-bb8d9cfda4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7fccb79-7338-4804-be9d-950c93bc70b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     70930\n",
      "           1       0.38      0.04      0.07      6284\n",
      "\n",
      "    accuracy                           0.92     77214\n",
      "   macro avg       0.65      0.52      0.51     77214\n",
      "weighted avg       0.88      0.92      0.88     77214\n",
      "\n",
      "Voting results for the first 20 samples:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Define target variable\n",
    "X = df.drop('Heart_Disease', axis=1)\n",
    "y = df['Heart_Disease']\n",
    "\n",
    "# Divide into training set and predicting set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Training\n",
    "rf_clf = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "#rf_clf.fit(X_train, y_train, feature_names=X_train.columns)\n",
    "\n",
    "# Pridicting and evaluate the model\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Print the accuracy\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the voting result of first 20th samples\n",
    "print('Voting results for the first 20 samples:')\n",
    "voting_results = rf_clf.predict(X_test.head(20))\n",
    "print(voting_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdaaea7-27b1-436f-bf04-a85addb9d4ec",
   "metadata": {},
   "source": [
    "## Inovation\n",
    "To deal with an imbalanced data set, we can adjust the voting system in a random forest model to make it easier to return the minority case. We can change the threshold by a for loop and determine which value is best for the threshold by analysing the report of each value. This is a new idea our group came up with and it is different from the traditional way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7fd741d-1ac4-42fb-b2d6-44efb5254bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0, Custom Accuracy: 0.5196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.49      0.65     70930\n",
      "           1       0.13      0.89      0.23      6284\n",
      "\n",
      "    accuracy                           0.52     77214\n",
      "   macro avg       0.56      0.69      0.44     77214\n",
      "weighted avg       0.91      0.52      0.62     77214\n",
      "\n",
      "Threshold: 1, Custom Accuracy: 0.6771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.67      0.79     70930\n",
      "           1       0.17      0.78      0.28      6284\n",
      "\n",
      "    accuracy                           0.68     77214\n",
      "   macro avg       0.57      0.72      0.54     77214\n",
      "weighted avg       0.91      0.68      0.75     77214\n",
      "\n",
      "Threshold: 2, Custom Accuracy: 0.7634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.77      0.86     70930\n",
      "           1       0.20      0.66      0.31      6284\n",
      "\n",
      "    accuracy                           0.76     77214\n",
      "   macro avg       0.58      0.71      0.58     77214\n",
      "weighted avg       0.90      0.76      0.81     77214\n",
      "\n",
      "Threshold: 3, Custom Accuracy: 0.8176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89     70930\n",
      "           1       0.23      0.53      0.32      6284\n",
      "\n",
      "    accuracy                           0.82     77214\n",
      "   macro avg       0.59      0.69      0.61     77214\n",
      "weighted avg       0.89      0.82      0.85     77214\n",
      "\n",
      "Threshold: 4, Custom Accuracy: 0.8543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92     70930\n",
      "           1       0.26      0.42      0.32      6284\n",
      "\n",
      "    accuracy                           0.85     77214\n",
      "   macro avg       0.60      0.66      0.62     77214\n",
      "weighted avg       0.89      0.85      0.87     77214\n",
      "\n",
      "Threshold: 5, Custom Accuracy: 0.8788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     70930\n",
      "           1       0.28      0.32      0.30      6284\n",
      "\n",
      "    accuracy                           0.88     77214\n",
      "   macro avg       0.61      0.62      0.62     77214\n",
      "weighted avg       0.89      0.88      0.88     77214\n",
      "\n",
      "Threshold: 6, Custom Accuracy: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     70930\n",
      "           1       0.31      0.23      0.27      6284\n",
      "\n",
      "    accuracy                           0.90     77214\n",
      "   macro avg       0.62      0.59      0.60     77214\n",
      "weighted avg       0.88      0.90      0.89     77214\n",
      "\n",
      "Threshold: 7, Custom Accuracy: 0.9059\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     70930\n",
      "           1       0.34      0.16      0.22      6284\n",
      "\n",
      "    accuracy                           0.91     77214\n",
      "   macro avg       0.63      0.57      0.58     77214\n",
      "weighted avg       0.88      0.91      0.89     77214\n",
      "\n",
      "Threshold: 8, Custom Accuracy: 0.9112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95     70930\n",
      "           1       0.35      0.10      0.16      6284\n",
      "\n",
      "    accuracy                           0.91     77214\n",
      "   macro avg       0.64      0.54      0.56     77214\n",
      "weighted avg       0.88      0.91      0.89     77214\n",
      "\n",
      "Threshold: 9, Custom Accuracy: 0.9149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     70930\n",
      "           1       0.37      0.07      0.11      6284\n",
      "\n",
      "    accuracy                           0.91     77214\n",
      "   macro avg       0.65      0.53      0.53     77214\n",
      "weighted avg       0.88      0.91      0.89     77214\n",
      "\n",
      "Threshold: 10, Custom Accuracy: 0.9166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     70930\n",
      "           1       0.38      0.04      0.07      6284\n",
      "\n",
      "    accuracy                           0.92     77214\n",
      "   macro avg       0.65      0.52      0.51     77214\n",
      "weighted avg       0.88      0.92      0.88     77214\n",
      "\n",
      "Threshold: 11, Custom Accuracy: 0.9176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     70930\n",
      "           1       0.38      0.02      0.04      6284\n",
      "\n",
      "    accuracy                           0.92     77214\n",
      "   macro avg       0.65      0.51      0.50     77214\n",
      "weighted avg       0.88      0.92      0.88     77214\n",
      "\n",
      "Threshold: 12, Custom Accuracy: 0.9182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     70930\n",
      "           1       0.39      0.01      0.02      6284\n",
      "\n",
      "    accuracy                           0.92     77214\n",
      "   macro avg       0.66      0.50      0.49     77214\n",
      "weighted avg       0.88      0.92      0.88     77214\n",
      "\n",
      "Threshold: 13, Custom Accuracy: 0.9184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     70930\n",
      "           1       0.37      0.00      0.01      6284\n",
      "\n",
      "    accuracy                           0.92     77214\n",
      "   macro avg       0.64      0.50      0.48     77214\n",
      "weighted avg       0.87      0.92      0.88     77214\n",
      "\n",
      "Threshold: 14, Custom Accuracy: 0.9185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     70930\n",
      "           1       0.36      0.00      0.00      6284\n",
      "\n",
      "    accuracy                           0.92     77214\n",
      "   macro avg       0.64      0.50      0.48     77214\n",
      "weighted avg       0.87      0.92      0.88     77214\n",
      "\n",
      "Threshold: 15, Custom Accuracy: 0.9186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     70930\n",
      "           1       0.56      0.00      0.00      6284\n",
      "\n",
      "    accuracy                           0.92     77214\n",
      "   macro avg       0.74      0.50      0.48     77214\n",
      "weighted avg       0.89      0.92      0.88     77214\n",
      "\n",
      "Threshold: 16, Custom Accuracy: 0.9186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     70930\n",
      "           1       1.00      0.00      0.00      6284\n",
      "\n",
      "    accuracy                           0.92     77214\n",
      "   macro avg       0.96      0.50      0.48     77214\n",
      "weighted avg       0.93      0.92      0.88     77214\n",
      "\n",
      "Threshold: 17, Custom Accuracy: 0.9186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     70930\n",
      "           1       1.00      0.00      0.00      6284\n",
      "\n",
      "    accuracy                           0.92     77214\n",
      "   macro avg       0.96      0.50      0.48     77214\n",
      "weighted avg       0.93      0.92      0.88     77214\n",
      "\n",
      "Threshold: 18, Custom Accuracy: 0.9186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     70930\n",
      "           1       0.00      0.00      0.00      6284\n",
      "\n",
      "    accuracy                           0.92     77214\n",
      "   macro avg       0.46      0.50      0.48     77214\n",
      "weighted avg       0.84      0.92      0.88     77214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 19, Custom Accuracy: 0.9186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     70930\n",
      "           1       0.00      0.00      0.00      6284\n",
      "\n",
      "    accuracy                           0.92     77214\n",
      "   macro avg       0.46      0.50      0.48     77214\n",
      "weighted avg       0.84      0.92      0.88     77214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 20, Custom Accuracy: 0.9186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     70930\n",
      "           1       0.00      0.00      0.00      6284\n",
      "\n",
      "    accuracy                           0.92     77214\n",
      "   macro avg       0.46      0.50      0.48     77214\n",
      "weighted avg       0.84      0.92      0.88     77214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "def custom_voting(votes, threshold):\n",
    "    # Convert votes to integers\n",
    "    votes = votes.astype(int)\n",
    "    # Count the votes for each class\n",
    "    counts = np.bincount(votes)\n",
    "    # If the count of class 1 is greater than the threshold, return 1, else return 0\n",
    "    return 1 if len(counts) > 1 and counts[1] > threshold else 0\n",
    "\n",
    "# Get the predictions for each sample in the test set\n",
    "predictions = np.array([tree.predict(X_test) for tree in rf_clf.estimators_]).T\n",
    "\n",
    "# Use the custom voting function to get the final predictions for thresholds from 0 to 20\n",
    "for threshold in range(21):\n",
    "    y_pred_custom = np.array([custom_voting(p, threshold) for p in predictions])\n",
    "    accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
    "    print(f'Threshold: {threshold}, Custom Accuracy: {accuracy_custom:.4f}')\n",
    "    print(classification_report(y_test, y_pred_custom))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc7e7b5-e65c-479c-bc5e-6da117e90d65",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "We used a for loop to gradually change the threshold from 0 to 20 and observe the performance of a random forest. We choose typical values here to illustrate： When the threshold is 0, it do increases the recall rate of 1 significantly but sacrifices the performance on ‘0’s too much which makes the overall accuracy not satisfying while a random forest model with va voting threshold of 3 has good overall accuracy with the ability to identify half of the patient.\n",
    "Compared to the Naive Bayes, we can see that while the threshold is 4, the Random Forest Model has  approximately the same recall rate of 1 class while the overall accuracy is larger than Naive Bayse's result with a difference of 2.5% which shows than random forest is a better model in this case.\n",
    "The doctor can set his/her own threshold to meet his/her needs. Refer to the report with different threshold values from 0 to 20 which makes the model more powerful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba9260-80f5-4116-b022-52af5258c553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
